{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from submit_Trimmomatic_SE import submit_Trimmomatic_SE\n",
    "from getAseqByBarcode import reads2uID\n",
    "from getA1seqByUID import queu_group_umi_seq\n",
    "from assembleUIDseq import assemble\n",
    "from filterContigs import filterContigs\n",
    "from submit_mothur import submit_mothur\n",
    "from mkdir import mkdir\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnnoTax(fa, final_tab,\n",
    "            mothur_db_fa, mothur_db_tax, mothur, \n",
    "            result_dir, threads=4):\n",
    "    logging.info(' taxonomy start')\n",
    "    submit_mothur(fa, mothur_db_fa, mothur_db_tax, mothur, threads)\n",
    "    tax_file = (re.search(r'(.*)\\.fasta',fa).group(1) + \n",
    "                re.search(r'(\\..*)\\.tax',mothur_db_tax).group(1) + \n",
    "                '.wang.taxonomy')\n",
    "    tax_ratio_file = os.path.join(result_dir, 'tax.ratio.xlsx')\n",
    "    tax_reads_file = os.path.join(result_dir, 'tax.reads.xlsx')\n",
    "    get_tax_from_mothur_with_level(tax_file,\n",
    "                                   final_tab,\n",
    "                                   tax_ratio_file,\n",
    "                                   tax_reads_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_from_mothur_with_level(tax_file, asv_file, tax_ratio_file, tax_reads_file):\n",
    "    '''统计物种分类结果\n",
    "    参数：\n",
    "        tax_file: mothur注释结果（.taxonomy文件）\n",
    "        asv_file: asv或者otu表格（每个asv或者otu的数量）\n",
    "        tax_ratio_file: 输出文件（物种序列比例）\n",
    "        tax_reads_file: 输出文件（物种序列数量）\n",
    "    返回：\n",
    "        无\n",
    "    '''\n",
    "    df_count = pd.DataFrame()\n",
    "    df_asv_reads = pd.read_csv(asv_file, sep='\\t', index_col=0)\n",
    "    df_asv_ratio = df_asv_reads / df_asv_reads.sum()\n",
    "    df_count['Contigs'] = df_asv_reads.sum()\n",
    "    df_count['Asv'] = (df_asv_ratio > 0).sum()\n",
    "    dict_tag = {'Kingdom': 0,\n",
    "                'Phylum': 1,\n",
    "                'Class': 2,\n",
    "                'Order': 3,\n",
    "                'Family': 4,\n",
    "                'Genus': 5,\n",
    "                'Species': 6}\n",
    "    dict_tag_r = dict(list((v, k) for k, v in dict_tag.items()))\n",
    "    df_asv_taxon = pd.read_csv(tax_file,\n",
    "                               sep='\\t',\n",
    "                               header=None,\n",
    "                               index_col=0)\n",
    "    df_asv_taxon.columns = (['Taxon'])\n",
    "    for pos, tax in dict_tag_r.items():\n",
    "        tmp_list = list(tax[0].lower() for i in range(df_asv_taxon.shape[0]))\n",
    "        df_asv_taxon[tax] = tmp_list\n",
    "        df_asv_taxon[tax] = df_asv_taxon[tax].str.cat(\n",
    "            df_asv_taxon['Taxon'].str.replace('\\(\\d+\\)', '').str.split(';').str[pos], sep='__')\n",
    "        if pos > 0:\n",
    "            df_asv_taxon[tax] = df_asv_taxon[dict_tag_r[pos - 1]].str.cat(df_asv_taxon[tax], sep=';')\n",
    "    df_asv_taxon.drop('Taxon', axis=1, inplace=True)\n",
    "    # df_asv_taxon['ID'] = pd.to_numeric(df_asv_taxon['Rep_Seq'].str.split('_').str[1])\n",
    "    # df_asv_taxon = df_asv_taxon.set_index('ID').drop('Rep_Seq',axis=1)\n",
    "    df_taxon_ratio = pd.merge(df_asv_ratio,\n",
    "                              df_asv_taxon,\n",
    "                              left_index=True,\n",
    "                              right_index=True)\n",
    "    df_taxon_reads = pd.merge(df_asv_reads,\n",
    "                              df_asv_taxon,\n",
    "                              left_index=True,\n",
    "                              right_index=True)\n",
    "    writer_ratio = pd.ExcelWriter(tax_ratio_file)\n",
    "    writer_reads = pd.ExcelWriter(tax_reads_file)\n",
    "    sample_name = list(df_asv_ratio.columns)\n",
    "    for tax in dict_tag.keys():\n",
    "        sample_name_tmp = list(df_asv_ratio.columns)\n",
    "        sample_name_tmp.append(tax)\n",
    "        df_tmp_ratio = df_taxon_ratio[sample_name_tmp].groupby([tax]).sum().reset_index().rename(\n",
    "            columns={tax: 'Taxonomy'})\n",
    "        df_tmp_ratio.insert(0, tax, df_tmp_ratio['Taxonomy'].str.split('__').str[-1])\n",
    "        df_tmp_reads = df_taxon_reads[sample_name_tmp].groupby([tax]).sum().reset_index().rename(\n",
    "            columns={tax: 'Taxonomy'})\n",
    "        df_tmp_reads.insert(0, tax, df_tmp_ratio['Taxonomy'].str.split('__').str[-1])\n",
    "        df_tmp_ratio.sort_values(by=sample_name, ascending=False).reset_index().drop('index', axis=1).to_excel(\n",
    "            writer_ratio, tax)\n",
    "        df_tmp_reads.sort_values(by=sample_name, ascending=False).reset_index().drop('index', axis=1).to_excel(\n",
    "            writer_reads, tax)\n",
    "        df_count[tax] = (df_tmp_ratio[sample_name] > 0).sum()\n",
    "    df_count.to_excel(writer_ratio, 'Sta')\n",
    "    df_count.to_excel(writer_reads, 'Sta')\n",
    "    writer_ratio.save()\n",
    "    writer_reads.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def BarcodeAna(A1, A_uID_file, A2_file=None, Fbarcode='F1', Rbarcode='R3', barcode_name='', out_dir='./', **kargs):\n",
    "    FB = Fbarcode\n",
    "    RB = Rbarcode\n",
    "    if barcode_name=='':\n",
    "        barcode_name = FB+\"_\"+RB\n",
    "    File_Tag_Barcode = out_dir #os.path.join(out_dir, barcode_name)\n",
    "    ana_dir = os.path.join(File_Tag_Barcode, 'analysis')\n",
    "    mkdir(File_Tag_Barcode)\n",
    "    mkdir(ana_dir)\n",
    "    \n",
    "    A1_file = os.path.join(ana_dir, 'A1.fastq.gz')\n",
    "    logging.info('trim A low quality start')\n",
    "    submit_Trimmomatic_SE(A1, A1_file, kargs['trimmomatic'], kargs['threads'])\n",
    "    \n",
    "    uIDseq_dir = os.path.join(ana_dir, barcode_name+\"_uIDseq\")\n",
    "    spades_path = os.path.join(ana_dir, barcode_name+'_spades')\n",
    "    spades_log_path = os.path.join(ana_dir, barcode_name+'_spades_log')\n",
    "\n",
    "    df_Aread2uID = pd.read_csv(A_uID_file, index_col=0)\n",
    "    df_Aread2uID = df_Aread2uID[df_Aread2uID['Sample']==str(FB)+'|'+str(RB)][['AreadID', 'umiID']]\n",
    "    \n",
    "#     uID_list = df_Aread2uID['umiID'].unique()[0:110]    ############  修改uID数量\n",
    "#     df_Aread2uID = df_Aread2uID[df_Aread2uID['umiID'].isin(uID_list)]\n",
    "    logging.info(\"uID count:\\t{}\".format(len(df_Aread2uID['umiID'].unique())))\n",
    "    \n",
    "    aUMI_dict = df_Aread2uID.set_index('AreadID').to_dict()['umiID']\n",
    "    Seq2uID_sta = queu_group_umi_seq(A1_file, uIDseq_dir, aUMI_dict)\n",
    "    if A2_file:\n",
    "        Seq2uID_sta = queu_group_umi_seq(A2_file, uIDseq_dir, aUMI_dict)\n",
    "    \n",
    "    mkdir(spades_path)\n",
    "    mkdir(spades_log_path)\n",
    "    tmp_list=[]\n",
    "    for tmp_dir in os.listdir(uIDseq_dir):\n",
    "        spades_path_tmp = os.path.join(spades_path, tmp_dir)\n",
    "        spades_log_tmp = os.path.join(spades_log_path, tmp_dir)\n",
    "        mkdir(spades_path_tmp)\n",
    "        mkdir(spades_log_tmp)\n",
    "        file_path_tmp = os.path.join(uIDseq_dir, tmp_dir)\n",
    "        files = list(map(lambda x:os.path.join(file_path_tmp,x),os.listdir(file_path_tmp)))\n",
    "        logging.info('assemble {} files from {} using {}\\t'\n",
    "                     .format(len(files), file_path_tmp, kargs['spades_py_path']))\n",
    "        tmp_list.append(assemble(files, spades_path_tmp, spades_log_tmp, kargs['spades_py_path']))\n",
    "    assmble_suc = [i[0] for i in tmp_list]\n",
    "    logging.info('Contigs assembled:\\t{}'.format(sum(assmble_suc)))\n",
    "    \n",
    "    \n",
    "    if sum(assmble_suc) == 0:\n",
    "        try:\n",
    "            sys.exit()\n",
    "        finally:\n",
    "            print('Exit with no contigs')\n",
    "    else:\n",
    "        final_tab, final_fa, c = filterContigs(spades_path, File_Tag_Barcode,\n",
    "                                                File_Tag=barcode_name, \n",
    "                                                minlength=1200, maxlength=1700,\n",
    "                                                cdhit=kargs['cdhit_path'],\n",
    "                                                cutadapt=kargs['cutadapt_path'],\n",
    "                                                usearch=kargs['usearch_path'],\n",
    "                                                file_primer_rc=kargs['file_primer_rc'],\n",
    "                                                file_primer=kargs['file_primer'],\n",
    "                                                threads=kargs['threads'],\n",
    "                                               )\n",
    "        \n",
    "        if c > 0:\n",
    "            AnnoTax(final_fa, final_tab, kargs['mothur_db_fa'], \n",
    "                    kargs['mothur_db_tax'], kargs['mothur_path'], \n",
    "                    File_Tag_Barcode, threads=kargs['threads'])\n",
    "    shutil.rmtree(ana_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
