{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "improved-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_umi_dict(df):\n",
    "    dup_idx = df[df.duplicated(subset=['umi_21','umi_11'], keep=False)].index\n",
    "    for i in dup_idx:\n",
    "        logging.info('duplicate umi paires:\\t{}'.format(df.loc[i].to_list()))\n",
    "    \n",
    "    df_dropdup = df.drop(dup_idx)\n",
    "    logging.info('umi paires:\\t{}'.format(df_dropdup.shape[0]))\n",
    "    \n",
    "    df_dropdup['umi_pair'] = df_dropdup['umi_21']+\"_\"+df_dropdup['umi_11']\n",
    "    umi_dict = df_dropdup.groupby('umi_pair')['Read name'].sum().to_dict()\n",
    "    umi1_dict = {}\n",
    "    umi2_dict = {}\n",
    "    for i,v in umi_dict.items():\n",
    "        u1 = i.split('_')[0]\n",
    "        u2 = i.split('_')[1]\n",
    "        umi1_dict[u1] = umi1_dict.get(u1, {})\n",
    "        umi1_dict[u1][u2] = v\n",
    "        umi2_dict[u2] = umi2_dict.get(u2, {})\n",
    "        umi2_dict[u2][u1] = v\n",
    "    return umi_dict, umi1_dict, umi2_dict\n",
    "\n",
    "def define_UMI_ID(UMI_dict, UMI1_dict, UMI2_dict, cutoff=0.5, min_counts=1):\n",
    "    ''' 根据连接文库序列的umi，定义umiID\n",
    "    参数：\n",
    "        UMI_dict: 连接文库所有umi配对关系及数量（type=dict）\n",
    "        UMI1_dict: 连接文库所有umi1对应的umi2及数量\n",
    "        UMI2_dict: 连接文库所有umi2对应的umi1及数量\n",
    "        cutoff: 可以作为umiID的配对关系所需要大于第一配对关系数量的最小比例\n",
    "        min_counts: 配对关系的最小数量\n",
    "    返回：\n",
    "        out_list: [umiID, umi1, umi2, counts]\n",
    "    '''\n",
    "    out_list = []\n",
    "    UMI_list = sorted(UMI_dict.items(), key=lambda UMI_dict: UMI_dict[1], reverse=True)\n",
    "    for idx_count in UMI_list:\n",
    "        if len(UMI1_dict) == 0:\n",
    "            break\n",
    "        (u1, u2) = idx_count[0].split('_')\n",
    "        if u1 in UMI1_dict.keys():\n",
    "            if len(UMI1_dict[u1]) == 0:\n",
    "                del UMI1_dict[u1]\n",
    "                continue\n",
    "            if u2 not in UMI2_dict.keys():\n",
    "                del UMI1_dict[u1][u2]\n",
    "                continue\n",
    "            if UMI1_dict[u1][u2] < min_counts:\n",
    "                logging.info('exit for {} counts {} < {}' \\\n",
    "                             .format(idx_count[0], UMI1_dict[u1][u2], min_counts))\n",
    "                break\n",
    "            out_list.append([idx_count[0], u1, u2, UMI1_dict[u1][u2]])\n",
    "            list1 = list(UMI2_dict[u2].keys())\n",
    "            list2 = list(UMI1_dict[u1].keys())\n",
    "            max_counts = UMI1_dict[u1][u2]\n",
    "            del UMI1_dict[u1]\n",
    "            del UMI2_dict[u2]\n",
    "            for deu in list1:\n",
    "                if deu in UMI1_dict.keys():\n",
    "                    if max(UMI1_dict[deu], key=UMI1_dict[deu].get) == u2:\n",
    "                        if UMI1_dict[deu][u2] >= cutoff * max_counts:\n",
    "                            out_list.append([idx_count[0], deu, u2, UMI1_dict[deu][u2]])\n",
    "                        del UMI1_dict[deu]\n",
    "            for deu in list2:\n",
    "                if deu in UMI2_dict.keys():\n",
    "                    if max(UMI2_dict[deu], key=UMI2_dict[deu].get) == u1:\n",
    "                        if UMI2_dict[deu][u1] >= cutoff * max_counts:\n",
    "                            out_list.append([idx_count[0], u1, deu, UMI2_dict[deu][u1]])\n",
    "                        del UMI2_dict[deu]\n",
    "    return out_list\n",
    "\n",
    "def dropRepeatUid(df, col1='umiID', col2='Barcode'):\n",
    "    df_count = df.groupby(col1)[col2].apply(lambda x: x.value_counts().to_list())\n",
    "    repeat_uid = df_count[df_count.apply(len)>1].index\n",
    "    \n",
    "    repeat_idx = df[df[col1].isin(repeat_uid)].index\n",
    "    logging.info('remain {} different barcode:\\t{}'.format(col1, df_count.shape[0]-len(repeat_uid)))\n",
    "    logging.info('remain {} count:\\t{}'.format(col1, df.shape[0]-len(repeat_idx)))\n",
    "    logging.info('repeat {} different barcode:\\t{}'.format(col1, len(repeat_uid)))\n",
    "    logging.info('repeat {} count:\\t{}'.format(col1, len(repeat_idx)))\n",
    "    logging.info('\\n{}'.format(df.loc[repeat_idx].groupby([col1,col2]).count()))\n",
    "    return df.drop(repeat_idx), df.loc[repeat_idx]\n",
    "\n",
    "\n",
    "def pairLumi(df):\n",
    "#     df = pd.read_csv(file, index_col=0)\n",
    "    umi_dict, umi1_dict, umi2_dict = get_umi_dict(df)\n",
    "    out_list = define_UMI_ID(umi_dict, umi1_dict, umi2_dict)\n",
    "\n",
    "    df_o = pd.DataFrame(out_list, columns=['umiID', 'umi_21', 'umi_11', 'Lreads'])\n",
    "    df_o = pd.merge(df_o.set_index(['umi_21','umi_11']), df.set_index(['umi_21','umi_11']), \n",
    "                    left_index=True, right_index=True, how='left'\n",
    "                   )\n",
    "    logging.info('uIDs in total barcode:\\t{}'.format(len(df_o['umiID'].unique())))\n",
    "    logging.info('uID paires in total barcode:\\t{}'.format(df_o.shape[0]))\n",
    "    df_o_dropRepeat, df_o_repeat = dropRepeatUid(df_o)\n",
    "    return df_o_dropRepeat.reset_index(), df_o_repeat.reset_index()\n",
    "\n",
    "def plot_Lreads(df_list, outfile_list):\n",
    "    for i, df in enumerate(df_list):\n",
    "        outfile = outfile_list[i] + '_uID_umiPaire_Lreads.png'\n",
    "        tmp_data = df.set_index('umiID')['Lreads']\n",
    "        plot_multiUMIreads(tmp_data, outfile=outfile)\n",
    "        \n",
    "        outfile = outfile_list[i] + '_uID_barcode_Lreads.png'\n",
    "        plot_umiID_Lreads(df, outfile=outfile)\n",
    "        \n",
    "        outfile = outfile_list[i] + '_uID_max_Lreads.png'\n",
    "        tmp_data = df.drop_duplicates(subset=['umiID'], keep='first').sort_values(by='Lreads', ascending=False)\n",
    "        plot_uID_each_Lreads(tmp_data, outfile=outfile)\n",
    "    \n",
    "    \n",
    "# logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s',level='INFO')\n",
    "# out_dir = '../test/out_dir_2/'\n",
    "# File_Tag='test'\n",
    "# # L_umi_info_file = os.path.join(out_dir, File_Tag+'_L_umi.csv')\n",
    "# # L_umi_sta = os.path.join(out_dir, File_Tag+'_L_umi_sta.csv')\n",
    "# # df_uID, df_uID_dropRepeat = pairLumi(L_umi_info_file)\n",
    "\n",
    "# L_uID_info_file = os.path.join(out_dir, File_Tag+'_L_uID_dropRepeat.csv')\n",
    "# # df_uID.to_csv(L_uID_info_file)\n",
    "# L_uID_info_Repeat_file = os.path.join(out_dir, File_Tag+'_L_uID_Repeat.csv')\n",
    "# # df_uID_dropRepeat.to_csv(L_uID_info_file)\n",
    "# df_uID = pd.read_csv(L_uID_info_file, index_col=0)\n",
    "# df_uID_repeat = pd.read_csv(L_uID_info_Repeat_file, index_col=0)\n",
    "# plot_Lreads([df_uID, df_uID_repeat], [os.path.join(out_dir, File_Tag+'_'+i) for i in ['dropRepeat', 'Repeat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greenhouse-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_uID_each_Lreads(df, outfile='uID_max_Lreads.png'):\n",
    "#     fig, ax = plt.subplots()\n",
    "#     tmp_data = df.reset_index().drop('index', axis=1)\n",
    "#     sns.lineplot(y='Lreads', x='index',data=tmp_data.reset_index(), ax=ax, label='Total')\n",
    "#     idx = df['Barcode'].value_counts().index[:10]\n",
    "#     for i in idx:\n",
    "#         tmp_data = df[df['Barcode']==i].reset_index().drop('index', axis=1)\n",
    "#         sns.lineplot(y='Lreads', x='index',data=tmp_data.reset_index(), ax=ax, label=i)\n",
    "#     plt.xlabel('range of uID')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# #     plt.tight_layout()\n",
    "# #     fig.savefig(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "arctic-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uID_each_Lreads(df, outfile='uID_max_Lreads.png'):\n",
    "    fig, ax = plt.subplots()\n",
    "    tmp_data = df.reset_index().drop('index', axis=1)\n",
    "    plt.plot(list(range(0, tmp_data.shape[0])), tmp_data['Lreads'], label='Total')\n",
    "    idx = df['Barcode'].value_counts().index[:10]\n",
    "    tmp_no = 0\n",
    "    y_max = tmp_data['Lreads'].max()\n",
    "    for i in idx:\n",
    "        tmp_data = df[df['Barcode']==i].reset_index().drop('index', axis=1)\n",
    "        plt.plot(range(tmp_no, tmp_no+tmp_data.shape[0]), tmp_data['Lreads'].to_list(), label=i)\n",
    "        tmp_no += tmp_data.shape[0] \n",
    "        plt.vlines(tmp_no, 0, y_max, linestyles='dashed', colors='grey', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xlabel('range of uID')\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    fig.savefig(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "czech-guard",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_multiUMIreads(data, max_col=10, outfile='uID_umiPaire_reads.png'):\n",
    "    df_tmp = data.groupby(level=0).apply(lambda x:x.to_list())\n",
    "    df_tmp = df_tmp.to_list()\n",
    "    max_len = max([len(i) for i in df_tmp])\n",
    "    if max_len>max_col:\n",
    "        max_len = max_col\n",
    "    np_o = np.zeros([len(df_tmp),max_len])\n",
    "    for i1,v1 in enumerate(df_tmp):\n",
    "        for i2,v2 in enumerate(v1):\n",
    "            if i2 < max_len:\n",
    "                np_o[i1,i2] = v2\n",
    "            else:\n",
    "                break\n",
    "    np_o = np.sort(np_o)[np.lexsort(np.sort(np_o).T, -1)][:,::-1]\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(np_o, cmap=\"YlGnBu\", ax=ax)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outfile)\n",
    "    \n",
    "\n",
    "# df_tmp = df_uID[df_uID.duplicated(subset='umiID', keep=False)].set_index('umiID')['Lreads']\n",
    "# plot_multiUMIreads(df_tmp)\n",
    "# plt.show()\n",
    "\n",
    "# df_tmp = df_uID_dropRepeat[df_uID_dropRepeat.duplicated(subset='umiID', keep=False)].set_index('umiID')['Lreads']\n",
    "# plot_multiUMIreads(df_tmp)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "widespread-diana",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_umiID_Lreads(df_umiID, min_umiID=100, outfile='uID_barcode_reads.png'):\n",
    "    df_uid_count = df_umiID.drop_duplicates(subset=['Barcode','umiID']).groupby('Barcode')['umiID'].count()\n",
    "    df_uid_Lreads = df_umiID.groupby('Barcode')['Lreads'].sum()\n",
    "    df_tmp = pd.merge(df_uid_count, df_uid_Lreads, left_index=True, right_index=True)\n",
    "    df_tmp = df_tmp.sort_values(by=['umiID','Lreads'], ascending=False)\n",
    "    df_tmp['Lreads/umiID'] = df_tmp['Lreads']/df_tmp['umiID']\n",
    "    df_tmp = df_tmp[df_tmp['umiID']>min_umiID]\n",
    "\n",
    "    fig, ax1 = plt.subplots(1,1)\n",
    "    plt.ylabel('#')\n",
    "    \n",
    "    ax1.plot(df_tmp['umiID'], c='b', label='umiID')\n",
    "    ax1.plot(df_tmp['Lreads'], c='g', label='Lreads')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    plt.ylabel('Lreads/uID')\n",
    "    ax2.plot(df_tmp['Lreads/umiID'], c='r', label='Lreads/umiID')\n",
    "    \n",
    "    plt.legend(loc='center right')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(outfile)\n",
    "\n",
    "# plot_umiID_Lreads(df_uID)\n",
    "# plot_umiID_Lreads(df_uID_dropRepeat)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
